Features

✅ Extracts MFCC features from speech audio

✅ Preprocesses dataset (TESS Toronto emotional speech set) for training

✅ Uses CNN architecture for emotion classification

✅ Trains the model on multiple emotional categories

✅ Evaluates performance and generates a classification report

✅ Saves and loads the trained model for future predictions


Tech Stack

🔹 Python (Librosa, NumPy, Pandas, Matplotlib, Seaborn)

🔹 Deep Learning (TensorFlow/Keras, CNN)

🔹 Machine Learning (Label Encoding, Train-Test Split)

🔹 Feature Extraction (MFCCs)

🔹 Model Storage & Deployment (Google Drive for saving models)


Usage

1️⃣ Extract speech features from .wav audio files using MFCCs.

2️⃣ Train CNN on labeled dataset for emotion recognition.

3️⃣ Evaluate accuracy and performance metrics using classification reports.

4️⃣ Make predictions on new speech samples.

5️⃣ Save and load trained models for future inference.

🚀 An advanced deep learning approach to recognizing human emotions from speech!

