Features

âœ… Extracts MFCC features from speech audio

âœ… Preprocesses dataset (TESS Toronto emotional speech set) for training

âœ… Uses CNN architecture for emotion classification

âœ… Trains the model on multiple emotional categories

âœ… Evaluates performance and generates a classification report

âœ… Saves and loads the trained model for future predictions


Tech Stack

ğŸ”¹ Python (Librosa, NumPy, Pandas, Matplotlib, Seaborn)

ğŸ”¹ Deep Learning (TensorFlow/Keras, CNN)

ğŸ”¹ Machine Learning (Label Encoding, Train-Test Split)

ğŸ”¹ Feature Extraction (MFCCs)

ğŸ”¹ Model Storage & Deployment (Google Drive for saving models)


Usage

1ï¸âƒ£ Extract speech features from .wav audio files using MFCCs.

2ï¸âƒ£ Train CNN on labeled dataset for emotion recognition.

3ï¸âƒ£ Evaluate accuracy and performance metrics using classification reports.

4ï¸âƒ£ Make predictions on new speech samples.

5ï¸âƒ£ Save and load trained models for future inference.

ğŸš€ An advanced deep learning approach to recognizing human emotions from speech!

